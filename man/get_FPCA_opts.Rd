% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/get_FPCA_opts.R
\name{get_FPCA_opts}
\alias{get_FPCA_opts}
\title{FPCA options settings}
\usage{
get_FPCA_opts(numVar, numCurves)
}
\arguments{
\item{numVar}{The number of functional data to fit.}

\item{numCurves}{The number of curves of a variable.}
}
\value{
An list of options to fit FPCA model used in \code{\link{FPCA}}.
}
\description{
Allow the users to set and examine a variety of FPCA options which affect
the way in which FPCA calculate its results.
}
\details{
For convinient explianation, we denote the number of variables (functions) as \code{p},
the number of curves of a variable (function) as \code{n}, the number of time points as \code{nt} and
the number of observations is denoted by \code{N (= n * nt)}.
The options of FPCA:
\itemize{
\item \code{bwMean}: A data.frame or data.table with two columns naming \code{variable} and \code{value}.
  Default value is \code{NULL}. If \code{bwMean} is \code{NULL},
  \code{bwMean = -1} will be used in all variables.
  First column is the names of variables. Second column is the value of \code{bwMean}.
  The \code{bwMean} for variables can be different. The value of \code{bwMean} can be following:
  \itemize{
    \item Any positive number: user-specified bandwidth.
    \item \code{-1}: Geometric mean of the minimum bandwidth and the GCV bandwidth. [default]
    \item \code{-2}: Use generalized cross-validation to choose bandwidth automatically.
  }
  For Gaussian/Epanechnikov kernel, the optimal bandwidth from GCV would be adjusted.
\item \code{bwCov}: A data.frame or data.table with four columns naming \code{variable1}, \code{variable2},
  \code{value1} and \code{value2}. Default value is \code{NULL}. If \code{bwCov} is \code{NULL},
  \code{bwCov = c(-1, -1)} will be used in all variables.
  First two columns is the names of variables. Last two column is the value of \code{bwCov}.
  The \code{bwCov} for variables can be different. The value of \code{bwCov} can be following:
  \itemize{
    \item Any positive number: user-specified bandwidth.
    \item \code{-1, -1}: Geometric mean of the minimum bandwidth and the GCV bandwidth.
    \item \code{-2, -2}: Use generalized cross-validation to choose bandwidth automatically.
      [default for the cases \code{variable1} is equal to \code{variable2}]
    \item \code{-3, -3}: Only used in choosing the bandwidth of Cross-Covariance. Use the bandwidths in
      smoothing covariance surface. [default for the cases \code{variable1} is not equal to \code{variable2}]
  }
  If a row is \code{-1, -2}, we only take \code{-1}.
  For Gaussian/Epanechnikov kernel, the optimal bandwidth from GCV would be adjusted.
\item \code{bwNumGrid}: Default is \code{30}.
   An integer is the number of support points of covariance surface. (for GCV)
  A smaller \code{bwNumGrid} accelerate process at less accuracy.
\item \code{bwKernel}: A character string to define the kernel to be used in the
  smoothing procedures of mean and covariance surface.
  \itemize{
    \item \code{epan}: Epanechnikov kernel, \code{f(x) = 0.75*(1-x^2), -1 <= x <= 1}.
       [Default for dense designs with n_i >= 20]
    \item \code{gauss}: Gaussian kernel, \code{f(x) = exp(-x^2/2)/sqrt(2*pi), -4 <= x <= 4}.
      [Default for sparse designs, regular designs with missings, dense designs for \code{n_i < 20}]
    \item \code{gaussvar}: A variant of Gaussian kernel,
      \code{f(x) = exp(-x^2/2)/sqrt(2*pi)*(1.25-x^2/4), -4 <= x <= 4}.
    \item \code{quar}: quartic kernel, \code{f(x) = (1-x^2)^2*15/16, -1 <= x <= 1}.
  }
  Note 1: The Gaussian kernel is overall best for sparse designs but is slower than the other kernels
    and if computational speed is of concern then one may wish to use the Epanechnikov kernel
    also for the case of sparse designs.
\item \code{numBins}: The number of bins to implement data binning.
  \itemize{
    \item Any positive integer (\code{>=10}): Use \code{numBins} to implement data binning.
    \item \code{-1}: Activate an automatic process to decide whether to implement data binning.
    \item \code{0}: Not implement data binning. [Default]
  }
\item \code{errTerm}: To indicate whether there is the measurement error in the model.
  \itemize{
    \item \code{FALSE}: no measurement error given in the model.
    \item \code{TRUE}: measurement error is given in the model. [Default]
  }
\item \code{numGrid}: Default is \code{51}. An integer, number of support points in each direction of
  covariance surface when performing functional principal component analysis.
  \code{numGrid} must be greater than the number of functional principal components (\code{numFPC}).
\item \code{weight}: sample weight used in the local weighted least-square.
  \itemize{
    \item \code{FALSE}: weights of all samples are \code{1}. [Default]
    \item \code{TRUE}: weights of all samples are the inverse of number of observation for each subject,
      ie, \code{1/ni}. If \code{weight} is used, the criterion \code{'AIC'}, \code{'BIC'} in \code{numFPC}
      will be calculated with \code{weight}.
  }
\item \code{numFPC}: A string or any real positive integer.
  \code{'AIC'}, \code{'BIC'}, \code{'FVE'} or \code{'AIC_R'} can be selected for selecting
  by one of these criterion. A real positive integer is also avaiable.
  \itemize{
    \item \code{AIC}: To use AIC with pseudo-likelihood of measurements (marginal likelihood).
    \item \code{BIC}: To use BIC with pseudo-likelihood of measurements (marginal likelihood).
    \item \code{FVE}: The fraction of variance explained. Use scree plot approach to select number of
      functional principal components. The threshold is set by \code{FVE_threshold}.
      Please see \code{FVE_threshold} below. [Default]
    \item \code{AIC_R}: It is set to be \code{numGrid}. (This option is default for the functional regression.)
    \item \code{Any positive integer}: A user-specified number of functional principal components.
  }
  Note: \code{'BIC'} and \code{'FVE'} produce the most parsimonious models.
\item \code{FVE_threshold}: A positive number is between 0 and 1. It is the fraction of variance explained.
  This option is only used in the case \code{numFPC} = \code{'FVE'} to select the number of functional
  principal components that explain at least \code{FVE_threshold} of total variation.
  [Default is 0.85.]
\item \code{maxNumFPC}: Default is \code{min(20, n-1)}. An integer, the maximum number of functional
  principal components. This option is only used in the case  \code{numFPC} = \code{'AIC'} or \code{'BIC'}.
  Otherwise, \code{maxNumFPC * numVar} will be used in the multivariate functional data.
\item \code{outPercent}: Default is \code{0}. A positive number is between \code{0} and \code{0.5}.
  This indicates that we will leave out \code{outPercent} data in the boundary.
  When performing local linear smoothing for mean functions and cross-covariance surface,
  all the data are used, but the output grid will be restricted within the reduced range.
  This option is used to alleviate the boundary effect.
\item \code{minMeasErr}: Default is \code{1e-6}. A numeric, the minimum of the measurement error variance.
\item \code{measErrOut}: Default is \code{0.5}. A positive number is between \code{0} and \code{0.5}.
  This indicates that we will leave out \code{measErrOut} data in the boundary for
  estimating the measurement error variance.
\item \code{methodFPCS}: A string, \code{'CE'}, \code{'IN'}, \code{'LS'} or \code{'WLS'}.
  The method to estimate fpc scores.
  \itemize{
    \item \code{CE}: The conditional expectation method is applied.
    \item \code{IN}: The integration method is applied.
    \item \code{LS}: The least-square method is applied.
    \item \code{WLS}: The weighted least-square method is applied. [Default]
  }
  Note: \code{'CE'}, \code{'LS'} or \code{'WLS'} can be applied for sparse data, irregular or regular data,
  but \code{'IN'} only be applied for regular data.
\item \code{rho}: A truncation threshold for the measurement error variance.
  This option is only used in the case \code{methodFPCS} = \code{'CE'}.
  \itemize{
    \item \code{cv}: To use a fixed rule to split the training data and validation data to
      find the optimal value of truncation threshold with cross-validation.
      (The results can be reproduced.) [Default]
    \item \code{cv-random}: To randomly split the training data and validation data to
      find the optimal value of truncation threshold with cross-validation.
      (The results can not be reproduced.)
    \item \code{no}: The truncation threshold will not be used.
    \item Any positive number: user-specified the measurement error variance.
  }
\item \code{shrink}: Whether to apply shrinkage method to estimate the FPC scores.
  (only for regular data.)
  \itemize{
    \item \code{TRUE}: The shrinkage method only used in the case \code{methodFPCS} = \code{'IN'} and
      \code{errTerm} = \code{TRUE}. Otherwise, this will be re-set to \code{FALSE}.
    \item \code{FALSE}: Not perform shrinkage method on eastimation of the FPC scores. [Default]
  }
\item \code{methodNorm}: The method to normalize the data.
  The default for univariate functional data is \code{'no'}.
  The default for multivariate functional data is \code{'quantile'}.
  \itemize{
    \item \code{no}: The normalization on data is not applied. Default value for univariate functional data.
    \item \code{quantile}: The normalization performed by substracting smoothed mean function and
      deviding by \code{0.75*IQR} of all curves. Default value for multivariate functional data.
    \item \code{smoothCov}: The normalization performed by substracting smoothed mean function and
      deviding by the variance of smoothed covariance surface. (Take the minimum positive value as threshold.).
      Please find the reference, Chiou, Chen and Yang. (2014), in \code{\link{rfda}}.
  }
\item \code{quantileProbs}: Default is \code{(0.25, 0.75)}.
  A positive numeric vector is between \code{0} and \code{1}.
  The probabilities of quantiles to approximate the variances.
  This option is only used in the case \code{methodNorm} = \code{'quantile'}.
\item \code{newdata}: A row vector of user-defined output time grids for all curves.
  This corresponds to \code{allTimePnts} in the output argument. If newdata is \code{NULL},
  then \code{allTimePnts} corresponds to the set of distinct time points from the pooled data.
  \code{newdata} is supposed to be a vector on the domain of the functions. The default is \code{NULL}.
\item \code{ncpus}: The number of threads used in computation.
  \itemize{
    \item \code{0}: To use all threads in computation. [Default]
    \item Any positive integer: To use user-specified number of threads in computation.
  }
\item \code{userMeanFunc}: Default is \code{NULL}. A data.table with three columns \code{timePnt}, \code{value}
  and \code{variable}. \code{value} is the mean function at specific time points.
  \code{timePnt} is the corresponding time points. \code{variable} is the name of observed variable.
  Please see the examples of \code{\link{FPCA}}.
\item \code{userCovFunc}: Default is \code{NULL}. A list of matrices with names \code{variable1}-\code{variable2}.
  The matrix is the cross-covariance surface of \code{variable1} and \code{variable2}.
  The colnames and rownames are the grid values of cross-covariance surface.
  If \code{userCovFunc} is given, \code{bwCov} must be given with real positive values of
  \code{value1} and \code{value2}.
  Please see the examples of \code{\link{FPCA}}.
}
}

